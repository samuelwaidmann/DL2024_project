{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n0jgHQDLBRD"
      },
      "source": [
        "#Description:\n",
        "In this notebook, we will explore LSTM models' accuracy in one-step-ahead (daily) weather forecast\n",
        "\n",
        "#Part 1: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YGXgKDTz7s50"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb2dXsjTaTAK",
        "outputId": "17742677-b5bb-4496-f670-c9b696f3806c"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLuuGZwrK-Ec",
        "outputId": "39395e67-c80b-41b6-d973-2de9e8fbd5d9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks/datasets/weather\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5OOKBOBLhwU"
      },
      "outputs": [],
      "source": [
        "#Reading data from Google Drive\n",
        "#This dataset is private, so I cannot share\n",
        "weather = pd.read_csv(\"drive/MyDrive/Colab Notebooks/datasets/weather/istanbul_historical_weather.csv\", on_bad_lines='skip')\n",
        "weather = weather[['datetime', 'tempmax', 'tempmin', 'temp', 'dew', 'humidity', 'precip', 'preciptype', 'windspeed', 'winddir', 'cloudcover']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B8OFlgObQzSH",
        "outputId": "c9b66c08-2e2a-4498-c4e9-90cc125d3f4c"
      },
      "outputs": [],
      "source": [
        "weather = weather.rename(columns={'temp': 'temperature', 'datetime': 'date'})\n",
        "weather['date'] = pd.to_datetime(weather['date'])\n",
        "weather.set_index('date')\n",
        "weather.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDHFQqJLK9k4"
      },
      "source": [
        "Data description:\n",
        "\n",
        "* date: YYYY-MM-DD\n",
        "\n",
        "* temperature: average temperature in Istanbul at the given date, in degrees Celcius\n",
        "\n",
        "* tempmax: maximum temperature in Istanbul at the given date, in degrees Celcius\n",
        "\n",
        "* tempmin: minimum temperature in Istanbul at the given date, in degrees Celcius\n",
        "\n",
        "* dew: dew point; required temperatuer to have dew in the air\n",
        "\n",
        "* humidity: average humiditiy in Istanbul at the given date, as percentage\n",
        "\n",
        "* precip: precipitation, in mm\n",
        "\n",
        "* preciptype: type of precipitation, such as rain, snow\n",
        "\n",
        "* windspeed: average windspeed in kilometers per hour\n",
        "\n",
        "* winddir: direction of the wind, 360$^\\circ$\n",
        "\n",
        "* cloudcover: percentage of sky covered in cloud, daily average\n",
        "\n",
        "Will be filling NA values of cloudcover with 0, NA values in precipitation type with None, and one-hot-encode precipitation type & month\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8a3zp2SSggK",
        "outputId": "8e027c77-fa16-4000-97d1-b98958668a9d"
      },
      "outputs": [],
      "source": [
        "weather['preciptype'] =  weather['preciptype'].fillna('None')\n",
        "weather['cloudcover'] =  weather['cloudcover'].fillna(0)\n",
        "weather.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5x-GTVWT_g0"
      },
      "source": [
        "There are only a few other NA values, deleting these rows will result negligible data loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT-rWxhWT63n",
        "outputId": "78caa2f8-18a9-4770-8ee7-d9b15e841f83"
      },
      "outputs": [],
      "source": [
        "weather.dropna(inplace=True)\n",
        "weather.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JwySobHUQFE"
      },
      "outputs": [],
      "source": [
        "weather['month'] = weather['date'].dt.month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "T2_CTiCHVhTf",
        "outputId": "28f7bb67-0bf5-4f6f-f29e-94f67d6e3af1"
      },
      "outputs": [],
      "source": [
        "weather.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCh7fJNsgZz8"
      },
      "source": [
        "Our main dataframe will be \"weather\". Let's examine the data even more:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "BlxMZ0ltghEA",
        "outputId": "5ed1ea6a-cfa5-43c2-ee24-8ed3c036349f"
      },
      "outputs": [],
      "source": [
        "weather_seperated = weather[['date', 'month', 'temperature']].copy(deep=True)\n",
        "weather_seperated['year'] = weather['date'].dt.year\n",
        "weather_seperated.drop(['date'], axis=1, inplace=True)\n",
        "weather_seperated = weather_seperated.pivot_table(index='month',  columns='year', values='temperature')\n",
        "weather_seperated.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "bvp1RYDlhA3N",
        "outputId": "eb83f9ea-f47e-4ab0-cc73-4774dfc1f96f"
      },
      "outputs": [],
      "source": [
        "weather_seperated.plot()\n",
        "plt.ylabel('Temperature (degrees Celcius)')\n",
        "plt.title(\"Istanbul's Monthly Temperature Averages, Each Line Represents a Year\")\n",
        "plt.legend().remove()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46atYAlTggVB"
      },
      "source": [
        "From the chart, we can see monthly temperature averages follow a meaningful seasonal trend.\n",
        "\n",
        "Note: legend is removed as there are 32 years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y7-9uYGShkGR",
        "outputId": "c9db10e4-6368-4dec-db2d-e68ed9432b20"
      },
      "outputs": [],
      "source": [
        "g = sns.PairGrid(weather[['temperature', 'dew', 'humidity', 'windspeed']])\n",
        "g.map(sns.scatterplot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6TZ3TgCk7w3"
      },
      "source": [
        "#Part 2: Checking the Naive prediction's error\n",
        "\n",
        "A naive temperature prediction would be \"tomorrow's average temperature will be the same with today\". We will check the error term when we use this prediction and use it as the benchmark of our LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Cv225lBz80k4",
        "outputId": "415ecc7f-3f4e-4256-95c4-ac74a2d8f552"
      },
      "outputs": [],
      "source": [
        "weather_naive = weather[['date', 'temperature']].copy(deep=True)\n",
        "weather_naive['prev_temperature'] = weather_naive['temperature'].shift(1)\n",
        "weather_naive.drop([0], inplace=True)\n",
        "weather_naive['difference'] = weather_naive['temperature'] - weather_naive['prev_temperature']\n",
        "weather_naive['square_error'] = weather_naive['difference'] ** 2\n",
        "weather_naive.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uulJ17kvlZAN",
        "outputId": "989eda8e-bc21-44ba-a660-0cc16162a23e"
      },
      "outputs": [],
      "source": [
        "square_error = weather_naive['square_error'].mean()\n",
        "print(f'Square Error of the Naive Approach is {square_error:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLfTRRVu-7CD"
      },
      "source": [
        "#Part 3: LSTM model for Weather Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "M2NRZDnD_DKE",
        "outputId": "c7e906cc-8a5f-42c2-9bed-9afad13dd840"
      },
      "outputs": [],
      "source": [
        "weather.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8fVwEXp5K--",
        "outputId": "fca11a5f-d93e-4821-f979-abc6606da6c8"
      },
      "outputs": [],
      "source": [
        "#One-hot-encoding precipitation type and month\n",
        "weather_LSTM = weather.copy(deep=True)\n",
        "weather_LSTM = pd.get_dummies(weather, columns = ['preciptype', 'month'])\n",
        "weather_LSTM.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "0gzawwGS_rDy",
        "outputId": "fe352796-ecd8-46c0-9d1f-54283140765d"
      },
      "outputs": [],
      "source": [
        "weather_LSTM.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E9ZIWbjEPEY"
      },
      "outputs": [],
      "source": [
        "input_data = weather_LSTM.drop(['date'], axis=1)\n",
        "targets = weather_LSTM['temperature'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2IGdU5-WyT6"
      },
      "source": [
        "We need to decide how many days' prior we need to see to predict today. Trial and error is a valid approach, but for this example I will be using 20 days as the target is not to get the best answer, just to check if LSTM is getting better predictions than the naive approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqZ1bFLCAPLW",
        "outputId": "056f1609-f6af-4b30-9b01-54dcce86bc3c"
      },
      "outputs": [],
      "source": [
        "T = 20                    #Number of timesteps to look while predicting\n",
        "D = input_data.shape[1]   #Dimensionality of the input\n",
        "N = len(input_data) - T\n",
        "print(f'Dimensions are {T} × {D} × {N}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PZTB4cEJ5Fs"
      },
      "outputs": [],
      "source": [
        "#Train size: 80% of the total data size\n",
        "train_size = int(len(input_data) * 0.80)\n",
        "\n",
        "# Normalization of the inputs\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(input_data[:train_size + T - 1])\n",
        "input_data = scaler.transform(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qTfk8GiZvs9"
      },
      "source": [
        "We need to create the train set and the test set and convert from numpy to torch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtLCmrcCKBqI"
      },
      "outputs": [],
      "source": [
        "# Preparing X_train and y_train\n",
        "X_train = np.zeros((train_size, T, D))\n",
        "y_train = np.zeros((train_size, 1))\n",
        "\n",
        "for t in range(train_size):\n",
        "  X_train[t, :, :] = input_data[t:t+T]\n",
        "  y_train[t] = (targets[t+T])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-cyxT_pZ9sx"
      },
      "outputs": [],
      "source": [
        "# Preparing X_test and y_test\n",
        "X_test = np.zeros((N - train_size, T, D))\n",
        "y_test = np.zeros((N - train_size, 1))\n",
        "\n",
        "for i in range(N - train_size):\n",
        "  t = i + train_size\n",
        "  X_test[i, :, :] = input_data[t:t+T]\n",
        "  y_test[i] = (targets[t+T])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGRN5su1YeRJ"
      },
      "outputs": [],
      "source": [
        "# Make inputs and targets\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYQUA7hqZ5n9"
      },
      "source": [
        "Using a classical LSTM structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV58DQ47aKBb"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.M = hidden_dim\n",
        "    self.L = layer_dim\n",
        "\n",
        "    self.rnn = nn.LSTM(\n",
        "        input_size=input_dim,\n",
        "        hidden_size=hidden_dim,\n",
        "        num_layers=layer_dim,\n",
        "        batch_first=True)\n",
        "    #batch_first to have (batch_dim, seq_dim, feature_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, X):\n",
        "    # initial hidden state and cell state\n",
        "    h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "    c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "\n",
        "    out, (hn, cn) = self.rnn(X, (h0.detach(), c0.detach()))\n",
        "\n",
        "    # h(T) at the final time step\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGG050oTaTlt"
      },
      "source": [
        "For the number of hidden layers, the recommendation is 1 for simple problems and 2 for complex features. As our time series is slightly complex, I will be using 2.\n",
        "\n",
        "Considering our training data size of 10,000 and input dimensionality; it's better to use hidden size at least 100 and at most 1000. 512 yielded good result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ahSMTxzaN5n",
        "outputId": "0928ce9c-f1b9-43b2-d88a-dfd65c6c47a7"
      },
      "outputs": [],
      "source": [
        "model = LSTM(D, 512, 2, 1)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVHrLfq5bgdX"
      },
      "source": [
        "At training, Adam optimizer failed to converge for a long time (started to converge at around 800th epoch). SGD with 0.9 momentum worked well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvYbvnwcaayz"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(model,\n",
        "          learning_rate,\n",
        "          X_train,\n",
        "          y_train,\n",
        "          X_test,\n",
        "          y_test,\n",
        "          epochs=200):\n",
        "\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "  train_losses = np.zeros(epochs)\n",
        "  test_losses = np.zeros(epochs)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #Train loss\n",
        "    train_losses[epoch] = loss.item()\n",
        "\n",
        "    # Test loss\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "    test_losses[epoch] = test_loss.item()\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "      print(f'At epoch {epoch+1} of {epochs}, Train Loss: {loss.item():.3f}, Test Loss: {test_loss.item():.3f}')\n",
        "\n",
        "  return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anMURjmVapdV"
      },
      "outputs": [],
      "source": [
        "# move data to GPU\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbXNZK9GarWY",
        "outputId": "319b2bd5-3361-4a92-db5b-5d19fae5ee8a"
      },
      "outputs": [],
      "source": [
        "train_losses, test_losses = train(model,\n",
        "                                    0.01,\n",
        "                                    X_train,\n",
        "                                    y_train,\n",
        "                                    X_test,\n",
        "                                    y_test,\n",
        "                                    epochs=750)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "fRWky5jrbrYP",
        "outputId": "44906b6f-b31c-45d1-9e22-e28793b4b731"
      },
      "outputs": [],
      "source": [
        "# Plot the train loss and test loss per iteration\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.xlabel('epoch no')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYo85qKecPHP"
      },
      "source": [
        "We don't see an overfitting pattern. It's possible to train the model a little more as we haven't started to see the seperation of train loss - test loss in a meaningful manner, but the gains will be minimal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4-L1tf9t94g"
      },
      "outputs": [],
      "source": [
        "#Checking one-step prediction performance of the model\n",
        "test_target = y_test.cpu().detach().numpy()\n",
        "test_predictions = []\n",
        "\n",
        "for i in range(len(test_target)):\n",
        "  input_ = X_test[i].reshape(1, T, D)\n",
        "  p = model(input_)[0,0].item()\n",
        "\n",
        "  # update the predictions list\n",
        "  test_predictions.append(p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Tz2LYgg_itAo",
        "outputId": "244cd4fa-1a25-4073-bc1f-fb88c40c1bb1"
      },
      "outputs": [],
      "source": [
        "plot_len = len(test_predictions)\n",
        "plot_df = weather[['date', 'temperature']].copy(deep=True)\n",
        "plot_df = plot_df.iloc[-plot_len:]\n",
        "plot_df['prediction'] = test_predictions\n",
        "plot_df.set_index('date', inplace=True)\n",
        "plot_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Fzbp4DDJ0R6C",
        "outputId": "284c4bbc-a9de-4e9c-9afd-7c952d59fdb5"
      },
      "outputs": [],
      "source": [
        "plt.plot(plot_df['temperature'], label='Actual Temperature', linewidth=1)\n",
        "plt.plot(plot_df['prediction'], label='One-step Prediction', linewidth=1)\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('temperature (degrees Celcius)')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zRLUbJRkrZa"
      },
      "source": [
        "We are seeing a good fit. However, it seems the model is not good at predicting rapid increase/decrease in temperature in a short-period of time (a few days)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp5eoQ7-lT9u",
        "outputId": "491678c3-d795-4ae9-8a2b-17d2975dc352"
      },
      "outputs": [],
      "source": [
        "LTSM_error = pd.DataFrame(test_target, columns = ['targets'])\n",
        "LTSM_error['predictions'] =test_predictions\n",
        "LTSM_error['error'] = LTSM_error['targets'] - LTSM_error['predictions']\n",
        "LTSM_error['error_square'] = LTSM_error['error'] ** 2\n",
        "err = LTSM_error['error_square'].mean()\n",
        "print(f'Mean square error is: {err:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "13FJ0zFAh3C7",
        "outputId": "2e2e4544-e678-43f0-9717-e0c3bc06d050"
      },
      "outputs": [],
      "source": [
        "plt.hist(LTSM_error['error'], bins=25)\n",
        "plt.xlabel('Temperature Difference (real - predictied)')\n",
        "plt.ylabel('count')\n",
        "plt.title('Distribution of Differences')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0oGC_G2iArv"
      },
      "source": [
        "#Discussion:\n",
        "\n",
        "The LSTM model is better in predicting one-step-ahead average weather in degrees celcius, in compare to the naive model. The naive model's error was 3.54, LSTM reduced it to 2.56.\n",
        "\n",
        "This model is not fine-tuned, so I believe further reduction in square error is possible. However, considering we only use data from Istanbul's previous weather (20-day) and weather prediction is complex, I believe it is not possible to reduce square error below 2.0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOQ6RT3zZnX3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
